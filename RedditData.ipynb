{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A python notebook for downloading subreddits aggregate counts for each day in a time range using Reddit's Pushshift API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://api.pushshift.io/reddit/submission/search/?subreddit=gardening&aggs=created_utc&after=2020-05-01&before=2020-05-10&limit=0\n",
    "def construct_url(subreddit, from_date, to_date):\n",
    "    '''\n",
    "    Constructs a reddit data aggregator url for downloading the data\n",
    "    \n",
    "    Args: base_url - reddit base_url\n",
    "          subreddit_name - name of the subreddit we want subbreddits for\n",
    "          from_date - date from which we need the data for the subreddit\n",
    "          to_date - date until which we need the data for the subreddit\n",
    "    Returns: returns a constructed url for getting the aggregates of the subreddit\n",
    "    '''\n",
    "    return 'http://api.pushshift.io/reddit/submission/search/?subreddit={subreddit_name}&aggs=created_utc&after={fromDate}&before={toDate}&limit=0'.format(subreddit_name = subreddit, fromDate = from_date, toDate = to_date)\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv(response, subreddit_name):\n",
    "    '''\n",
    "    Returns a CSV file from a reddit URL with aggregate data of a subreddit\n",
    "    \n",
    "    Args:response - response from a URL\n",
    "    \n",
    "    Returns: a csv file\n",
    "    '''    \n",
    "    # Get the Json into a dict format for csv file conversion\n",
    "    response_dict = response.json()['aggs']['created_utc']\n",
    "    df = pd.DataFrame(response_dict, index = None)\n",
    "    #converting epoch time to real time for data analysis\n",
    "    df['key'] = pd.to_datetime(df['key'],unit='s')\n",
    "    \n",
    "    #reindexing the columns\n",
    "    dataframe = df[['key', 'doc_count']]\n",
    "    \n",
    "    #writing the data to a CSV file\n",
    "    dataframe.to_csv(r'C:\\Data\\\\{subredditName}.csv'.format(subredditName=subreddit_name), index=False)\n",
    "    \n",
    "    return \"CSV file has been downloaded for r/{subredditName} at C:\\Data\\\\\".format(subredditName = subreddit_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://api.pushshift.io/reddit/submission/search/?subreddit='\n",
    "subreddits = ['gardening', 'recipes', 'embroidery', 'sewing', 'cooking', 'fitness', 'running', 'suggestmeabook', 'hiking', 'camping', 'nakedadventures', 'backpacking', 'baking', 'grilling',\n",
    "             'stargazing', 'meditation', 'calligraphy', 'yoga', 'knitting', 'crocheting', 'bodyweightfitness', 'dataisbeautiful']\n",
    "\n",
    "from_date = '2020-01-01'\n",
    "to_date = '2020-06-10'\n",
    "\n",
    "for sub in subreddits1:\n",
    "    url = construct_url(sub, from_date, to_date)\n",
    "        \n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        generate_csv(r, sub)\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print (\"Http Error:\",errh)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print (\"Error Connecting:\",errc)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print (\"Timeout Error:\",errt)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print (\"OOps: Something Else\",err)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
